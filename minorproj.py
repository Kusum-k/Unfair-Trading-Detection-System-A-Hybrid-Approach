# -*- coding: utf-8 -*-
"""MinorProj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VDLt7w5DHPGG3Vxl2ghhJjN90FqDe5RX
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('ADANIPORTS.csv')
df.head()

print(df.isnull().sum())

df = df.dropna()

if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])

df = df.reset_index(drop=True)

df = df.drop_duplicates()

df.head()

cleaned_path = '/content/ADANIPORTS_cleaned.csv'
df.to_csv(cleaned_path, index=False)

from google.colab import files
files.download(cleaned_path)

"""ADD COLUMN"""

import pandas as pd

file_path = 'ADANIPORTS_cleaned.csv'
df = pd.read_csv(file_path)

df['price_item'] = df['Close'].diff().apply(lambda x: 'up' if x > 0 else 'down' if x < 0 else 'no change')

df = df[df['price_item'] != 'no change']

df.to_csv('ADANIPORTS_with_price_item.csv', index=False)

df[['Close', 'price_item']].head()

print(df.columns)

from google.colab import files
files.download('ADANIPORTS_with_price_item.csv')

"""P value analysis"""

import pandas as pd
import numpy as np
from scipy import stats

df = pd.read_csv('ADANIPORTS_with_price_item.csv')
if 'Date' in df.columns:
    df['Date'] = pd.to_datetime(df['Date'])

df.head()

df['Return'] = df['Close'].pct_change()
df = df.dropna(subset=['Return'])

t_stat, p_value = stats.ttest_1samp(df['Return'], 0)

print(f"T-statistic: {t_stat}")
print(f"P-value: {p_value}")

alpha = 0.05
if p_value < alpha:
    print("Reject the null hypothesis: The average return is significantly different from 0.")
else:
    print("Fail to reject the null hypothesis: No significant evidence that average return differs from 0.")

"""CONFIDENCE INTERVAL

"""

mean_return = df['Return'].mean()
std_error = stats.sem(df['Return'])

confidence_level = 0.95

margin = std_error * stats.t.ppf((1 + confidence_level) / 2., len(df['Return']) - 1)

ci_lower = mean_return - margin
ci_upper = mean_return + margin

print(f"Mean Daily Return: {mean_return:.6f}")
print(f"{int(confidence_level * 100)}% Confidence Interval: ({ci_lower:.6f}, {ci_upper:.6f})")

"""Machine learning

Scikit-learn  code
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import LabelEncoder
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from google.colab import files

uploaded = files.upload()

df = pd.read_csv("ADANIPORTS_with_price_item.csv")

label_encoder = LabelEncoder()
df['price_item_encoded'] = label_encoder.fit_transform(df['price_item'])

X = df.select_dtypes(include=['float64', 'int64']).drop(columns=['price_item_encoded'])
y = df['price_item_encoded']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

dt_model = RandomForestClassifier(random_state=42)
dt_model.fit(X_train, y_train)
dt_preds = dt_model.predict(X_test)
dt_accuracy = accuracy_score(y_test, dt_preds)
print(" Random Forest Accuracy:", round(dt_accuracy * 100, 2), "%")

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
dt_preds = dt_model.predict(X_test)
dt_accuracy = accuracy_score(y_test, dt_preds)
print(" Decision Tree Accuracy:", round(dt_accuracy * 100, 2), "%")

"""Pycaret code

"""

!pip install --upgrade pycaret

import pandas as pd
from pycaret.classification import *

from google.colab import files
uploaded = files.upload()

df = pd.read_csv('ADANIPORTS_with_price_item.csv')
print(df.columns)

df.rename(columns={"Price_Trend": "price_trend"}, inplace=True)

df.drop(columns=["Date"], inplace=True)

print(df.columns)

df.columns = df.columns.str.strip()
df.dropna(inplace=True)

clf = setup(df, target="price_item", session_id=123)

best_model = compare_models()
evaluate_model(best_model)

print("Best Model Selected by PyCaret:")
print(best_model)

"""FALSE DISCOVERY RATE FDR"""

!pip install pandas numpy scipy statsmodels

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
from statsmodels.stats.multitest import fdrcorrection

df = pd.read_csv('ADANIPORTS_with_price_item.csv')

import numpy as np
from scipy.stats import ttest_ind

print(df.columns)

if 'Close' in df.columns:
    if df['Close'].dtype in ['int64', 'float64']:
        p_values = []

        for i in range(df.shape[1]):
            if df.iloc[:, i].dtype in ['int64', 'float64']:
                p_value = ttest_ind(df['Close'], df.iloc[:, i])[1]
                p_values.append(p_value)

        p_values = np.array(p_values)
    else:
        print("'Close' is not numeric.")
else:
    print("Close does not exist in the DataFrame.")

reject, pvals_corrected = fdrcorrection(p_values, alpha=0.05)

for i in range(len(pvals_corrected)):
    print(f"Test {i+1} - p-value: {p_values[i]}, Corrected p-value: {pvals_corrected[i]}, Reject null hypothesis: {reject[i]}")

"""Sentiment analysis"""

!pip install pandas

import pandas as pd
import random

from google.colab import files
uploaded = files.upload()

import io
df = pd.read_csv(io.BytesIO(uploaded['ADANIPORTS_with_price_item.csv']))

down_headlines = [
    "Adani Ports stock faces slight decline amid market pressure.",
    "Investors cautious as Adani Ports slips again.",
    "Weak demand drives Adani Ports shares downward.",
    "Market volatility leads to drop in Adani Ports stock.",
    "Negative sentiment weighs on Adani Ports performance."
]

up_headlines = [
    "Adani Ports stock rises on strong trading volume.",
    "Positive market cues boost Adani Ports shares.",
    "Adani Ports sees upward trend amid investor optimism.",
    "Strong fundamentals push Adani Ports stock higher.",
    "Adani Ports gains momentum in bullish market."
]

def generate_headline(label):
    if str(label).lower() == 'down':
        return random.choice(down_headlines)
    elif str(label).lower() == 'up':
        return random.choice(up_headlines)
    else:
        return "No headline available."

df['news_headline'] = df['price_item'].apply(generate_headline)

df[['Date', 'price_item', 'news_headline']].head()

print(df.columns)

!pip install vaderSentiment

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()

def get_sentiment(text):
    if pd.isna(text):
        return None
    return analyzer.polarity_scores(text)['compound']

df['sentiment_score'] = df['news_headline'].apply(get_sentiment)

df[['Date', 'news_headline', 'sentiment_score']].head()

def classify_sentiment(score):
    if score >= 0.05:
        return 'Positive'
    elif score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

df['sentiment_label'] = df['sentiment_score'].apply(classify_sentiment)

df[['Date', 'news_headline', 'sentiment_score', 'sentiment_label']].head(10)

df['Date'] = pd.to_datetime(df['Date'])

import matplotlib.pyplot as plt

df.groupby(df['Date'].dt.date)['sentiment_score'].mean().plot(
    figsize=(12,6), title="Average Sentiment Over Time", grid=True)
plt.xlabel("Date")
plt.ylabel("Sentiment Score")
plt.show()

df.to_csv("ADANIPORTS_with_sentiment_label.csv", index=False)
files.download("ADANIPORTS_with_sentiment_label.csv")